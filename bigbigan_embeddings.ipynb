{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "dim_z = 120\n",
    "\n",
    "\n",
    "DATA_DIR = '__place_path_to_images_root__'\n",
    "EMBEDDINGS_FILE = '__output_file__'\n",
    "\n",
    "\n",
    "# Load BigBiGAN module.\n",
    "module = hub.Module('https://tfhub.dev/deepmind/bigbigan-resnet50/1')  # small encoder\n",
    "# module = hub.Module('https://tfhub.dev/deepmind/bigbigan-revnet50x4/1')  # large encoder\n",
    "\n",
    "z = tf.random.truncated_normal([24, 120])  # latent samples\n",
    "gen_samples = module(z, signature='generate')\n",
    "\n",
    "images = tf.placeholder(tf.float32, shape=[None, 256, 256, 3])\n",
    "features = module(images, signature='encode', as_dict=True)\n",
    "z_sample = features['z_sample']  # shape [?, 120]\n",
    "\n",
    "recons = module(z_sample, signature='generate')  # shape [?, 128, 128, 3]\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "initializer = tf.global_variables_initializer()\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from data import UnannotatedDataset\n",
    "\n",
    "ds = UnannotatedDataset(\n",
    "    DATA_DIR,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        lambda x: (2.0 * x - 1.0).permute(1, 2, 0).numpy()\n",
    "    ]))\n",
    "\n",
    "\n",
    "gen_np = np.stack([ds[i] for i in range(0, 10)])\n",
    "recons_np = sess.run(recons, feed_dict={images: gen_np})\n",
    "\n",
    "plt.figure(figsize=(10, 2), dpi=200)\n",
    "batch = gen_np.shape[0]\n",
    "\n",
    "for i in range(batch):\n",
    "    plt.subplot(2, len(gen_np), i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(0.5 * gen_np[i] + 0.5)\n",
    "\n",
    "    plt.subplot(2, len(gen_np), len(gen_np) + i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(0.5 * recons_np[i] + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "batch_size = 100\n",
    "emdeddings = []\n",
    "\n",
    "all_indices = np.arange(0, len(ds))\n",
    "count = len(all_indices)\n",
    "for batch_start in tqdm_notebook(np.arange(0, count, batch_size), total=count // batch_size):\n",
    "    low, up = batch_start, min(batch_start + batch_size, count)\n",
    "    gen_np = np.stack([ds[i] for i in all_indices[low: up]])\n",
    "    emdeddings.append(sess.run(features, feed_dict={images: gen_np}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = [e['z_sample'] for e in emdeddings]\n",
    "zs = np.vstack(zs)\n",
    "np.save(EMBEDDINGS_FILE, zs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
